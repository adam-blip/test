{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOr1E/nhL5uvBZxqziPaRtV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adam-blip/test/blob/master/hdr%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stacking low light images for hdr creation\n",
        "\n",
        "In this notebook, we will perform the following steps:\n",
        "\n",
        "1. **Load and Preprocess the Image**:\n",
        "   - Load an image from the `dataset` folder.\n",
        "   - Extract a random patch of at least half the original size.\n",
        "   - Perform various augmentations on the patch.\n",
        "\n",
        "2. **Augment the Image**:\n",
        "   - Apply transformations such as rotation, flipping, color and brightness adjustments, noise addition, and darkening to simulate night images.\n",
        "   - Repeat this process to create a total of 5 augmented images.\n",
        "\n",
        "3. **Build the Model**:\n",
        "   - Construct a TensorFlow Keras model with 2 residual blocks and channel attention.\n",
        "   - The model will take 5 input images and produce a single output image.\n",
        "\n",
        "4. **Train the Model**:\n",
        "   - Train the model for 100 epochs, minimizing the mean squared error (MSE) between the output image and the original image.\n",
        "   - Visualize the training process every epoch.\n",
        "\n",
        "5. **Convert to TensorFlow Lite**:\n",
        "   - Convert the trained model to TensorFlow Lite format with quantization for efficient inference on low-budget phones.\n",
        "\n",
        "6. **Test Inference Speed**:\n",
        "   - Compare the inference speed of the original model and the quantized TensorFlow Lite model.\n"
      ],
      "metadata": {
        "id": "yvtDD05au3AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "from skimage.util import random_noise\n",
        "from skimage.transform import rotate, rescale\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "import time\n",
        "\n",
        "# Define paths and constants\n",
        "dataset_folder = 'dataset'\n",
        "image_path = os.path.join(dataset_folder, os.listdir(dataset_folder)[0])  # Load the first image in the dataset folder\n",
        "\n",
        "# Load the image\n",
        "original_image = imread(image_path)\n",
        "original_image_float = original_image.astype('float32') / 255.0\n",
        "\n",
        "# Function to extract a random patch\n",
        "def extract_random_patch(image, min_size=0.5):\n",
        "    height, width, _ = image.shape\n",
        "    min_dim = int(min(height, width) * min_size)\n",
        "    patch_height = np.random.randint(min_dim, height)\n",
        "    patch_width = np.random.randint(min_dim, width)\n",
        "    y = np.random.randint(0, height - patch_height)\n",
        "    x = np.random.randint(0, width - patch_width)\n",
        "    return image[y:y+patch_height, x:x+patch_width]\n",
        "\n",
        "# Function to augment the image\n",
        "def augment_image(image):\n",
        "    # Random rotation\n",
        "    angle = np.random.uniform(-25, 25)\n",
        "    image = rotate(image, angle)\n",
        "\n",
        "    # Random flipping\n",
        "    if np.random.rand() > 0.5:\n",
        "        image = np.fliplr(image)\n",
        "    if np.random.rand() > 0.5:\n",
        "        image = np.flipud(image)\n",
        "\n",
        "    # Random color and brightness adjustment\n",
        "    image_hsv = rgb2hsv(image)\n",
        "    image_hsv[:, :, 1] *= np.random.uniform(0.5, 1.5)  # Adjust saturation\n",
        "    image_hsv[:, :, 2] *= np.random.uniform(0.5, 1.5)  # Adjust brightness\n",
        "    image = hsv2rgb(image_hsv)\n",
        "\n",
        "    # Add random noise\n",
        "    image = random_noise(image, mode='gaussian', var=0.01)\n",
        "\n",
        "    # Darken the image to simulate night\n",
        "    image = np.clip(image * np.random.uniform(0.5, 1.0), 0, 1)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Extract a random patch from the original image\n",
        "patch = extract_random_patch(original_image_float)\n",
        "\n",
        "# Generate augmented images\n",
        "augmented_images = [patch]\n",
        "for _ in range(4):\n",
        "    augmented_images.append(augment_image(augmented_images[-1]))\n",
        "\n",
        "# Plot the original and augmented images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, img in enumerate([original_image_float] + augmented_images):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Image {i}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Define a residual block with channel attention\n",
        "def residual_block(x, filters):\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def channel_attention(x, filters):\n",
        "    avg_pool = layers.GlobalAveragePooling2D()(x)\n",
        "    max_pool = layers.GlobalMaxPooling2D()(x)\n",
        "    avg_pool = layers.Reshape((1, 1, filters))(avg_pool)\n",
        "    max_pool = layers.Reshape((1, 1, filters))(max_pool)\n",
        "    shared_layer_one = layers.Dense(filters // 2, activation='relu')\n",
        "    shared_layer_two = layers.Dense(filters, activation='sigmoid')\n",
        "    avg_pool = shared_layer_two(shared_layer_one(avg_pool))\n",
        "    max_pool = shared_layer_two(shared_layer_one(max_pool))\n",
        "    cbam_feature = layers.Add()([avg_pool, max_pool])\n",
        "    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n",
        "    return layers.Multiply()([x, cbam_feature])\n",
        "\n",
        "# Build the model\n",
        "input_shape = augmented_images[0].shape\n",
        "inputs = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "x = residual_block(x, 64)\n",
        "x = channel_attention(x, 64)\n",
        "x = residual_block(x, 64)\n",
        "x = channel_attention(x, 64)\n",
        "outputs = layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Prepare the data\n",
        "augmented_images = np.array(augmented_images)\n",
        "target_image = np.expand_dims(patch, axis=0)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(augmented_images, target_image, epochs=100, verbose=1)\n",
        "\n",
        "# Visualize training process\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Convert the model to TensorFlow Lite with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Test inference speed\n",
        "def test_inference_speed(model, input_data, num_runs=100):\n",
        "    start_time = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        model.predict(input_data)\n",
        "    end_time = time.time()\n",
        "    return (end_time - start_time) / num_runs\n",
        "\n",
        "# Original model inference speed\n",
        "original_model_time = test_inference_speed(model, augmented_images)\n",
        "print(f'Original model inference time: {original_model_time:.6f} seconds')\n",
        "\n",
        "# TFLite model inference speed\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "def tflite_inference(interpreter, input_data):\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data\n",
        "\n",
        "tflite_model_time = test_inference_speed(lambda x: tflite_inference(interpreter, x), augmented_images)\n",
        "print(f'TFLite model inference time: {tflite_model_time:.6f} seconds')\n"
      ],
      "metadata": {
        "id": "jc1Lh81Ovvz2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}